
LLM_API_KEY=XXXXXX

# LLM_PROVIDER=ollama
LLM_PROVIDER=groq
# MODEL=phi3
MODEL=meta-llama/llama-4-scout-17b-16e-instruct

#Ollama specific
OLLAMA_HOST=http://host.docker.internal:11434


#implementation for openai pending
