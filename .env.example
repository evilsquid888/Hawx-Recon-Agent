LLM_API_KEY='ENTER YOUR GROK API KEY HERE'
LLM_PROVIDER='ENTER YOU LLM PROVIDER HERE'

#Grok specific
GROK_MODEL="GROQ_MODEL"

#Ollama specific:
OLLAMA_MODEL=qwen2.5
OLLAMA_HOST=http://host.docker.internal:11434



#rename this to .env
#implementation for openai pending